---
title: "Homework 3"
author: "Matthew T. Russell"
date: "10/20/2021"
output: github_document
---

```{r setup, load packages, include = FALSE}
library(tidyverse)
library(p8105.datasets)
library(lubridate)
library(knitr)
library(patchwork)
library(ggridges)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

# Problem 1

##### Load Instacart data

```{r, load data in, message=FALSE}
data("instacart")

instacart <-
  instacart %>% 
  mutate(
    order_dow = order_dow + 1,
    order_dow = wday(order_dow, label = T)  
    )
```

There are `r nrow(instacart)` observations and `r ncol(instacart)` columns in the `instacart` data where each observation represents a product that was purchased as part of an Instacart order. Key variables include:

*`reordered`: binary variable indicating if a user has ordered the product in the past  
*`order_dow`: the day of the week the order was placed  
*`order_hour_of_day`: the hour the order was placed  
*`days_since_prior_order`: the number of days since the user placed their last order with the maximum being 30 and NA if it's  the user's first order  

##### Illustrative examples

###### Bar plot: products ordered by dept

```{r, bar plot products dept, message=FALSE}
dept_products_total <-
  instacart %>% 
  group_by(department) %>% 
  summarize(
    n_obs = n()
  ) %>% 
  arrange(desc(n_obs)) %>% 
  filter(department != 'missing')

dept_products_total %>% 
  ggplot(aes(x = reorder(department, n_obs), y = n_obs, fill = n_obs)) +
    geom_bar(stat = "identity") + 
    xlab("Department") + ylab("Count") +
    coord_flip() +
    theme(
      legend.position = "none"
          ) +
    ggtitle(label = "Products Ordered by Department")
```

The five departments with the most purchased products are `r head(pull(dept_products_total, department), 5)`, and the five departments with the least purchased products are `r tail(pull(dept_products_total, department), 5)`.

###### Number of orders by time of day and day of week

```{r, col plot time of day and dow, message=FALSE}
order_time_by_day <-
  instacart %>% 
    select(order_id, order_dow, order_hour_of_day) %>% 
    distinct %>% 
    mutate(
      time_of_day =
        ifelse(order_hour_of_day %in% 5:11, "morning", 
          ifelse(order_hour_of_day %in% 12:16, "afternoon", 
            ifelse(order_hour_of_day %in% 17:20, "evening", "night")
          )
        ) %>% 
      factor(levels = c("morning", "afternoon", "evening", "night"))
      ) %>% 
    group_by(time_of_day, order_dow) %>% 
    summarize(
      n_orders = n()
    ) %>% 
    arrange(desc(n_orders))

total_orders_per_day <-
  order_time_by_day %>% 
  group_by(order_dow) %>% 
  summarize(
    total_orders = sum(n_orders)
  ) %>% 
  arrange(desc(total_orders))

order_time_by_day %>% 
  ggplot(aes(x = order_dow, y = n_orders , fill = time_of_day)) +
    geom_col() +
    xlab("Day of Week") + ylab("Order Count") +
    labs(fill = "Time of Day") +
    ggtitle(label = "Order Quantity by Day of Week")

```

To find out how many orders were placed at each time of day, I considered 5 AM to 11 AM morning, 12 PM to 4 PM afternoon, 5 PM to 8 PM evening, and 9 PM to 4 AM night. The day with the most orders overall was `r head(pull(total_orders_per_day, order_dow), 1)`. with `r head(pull(total_orders_per_day, total_orders), 1)` orders, and the day with the least orders overall was `r tail(pull(total_orders_per_day, order_dow), 1)`. with `r tail(pull(total_orders_per_day, total_orders), 1)` orders. The most popular time to place an order was `r head(pull(order_time_by_day, order_dow), 1)`. `r head(pull(order_time_by_day, time_of_day), 1)` with `r head(pull(order_time_by_day, n_orders), 1)` orders placed, and the least popular time to place an order was `r tail(pull(order_time_by_day, order_dow), 1)`. `r tail(pull(order_time_by_day, time_of_day), 1)` with `r tail(pull(order_time_by_day, n_orders), 1)` orders placed.


#### How many aisles are there, and which aisles are the most items ordered from?

```{r, message=FALSE}
aisles <-
  instacart %>% 
    count(aisle, name = "total_items_ordered", sort = T)
```

There are `r nrow(aisles)` aisles in the `instacart` data. The top five aisles ordered from are
`r head(pull(aisles, aisle), 5)`.


#### Make a plot that shows the number of items ordered in each aisle, limiting this to aisles with more than 10000 items ordered. Arrange aisles sensibly, and organize your plot so others can read it.

```{r, message=FALSE}
aisles %>% 
  filter(total_items_ordered > 10000) %>% 
  ggplot(aes(x = reorder(aisle, total_items_ordered), y = total_items_ordered)) +
    geom_bar(stat = "identity", aes(fill = total_items_ordered)) + 
    xlab("Aisle") + ylab("Count") +
    theme(axis.text.y = element_text(size = 7),
          legend.position = "none") +
    coord_flip() +
    ggtitle(label = "Number of Items Ordered per Aisle")
```

Of items that have been purchased over 10000 times, the aisle with the most items ordered are `fresh vegetables`, and the aisle with the least items ordered is `butter`. There are only two aisles with over 100000 products ordered are `fresh vegetables` and `fresh fruits`.

#### Make a table showing the three most popular items in each of the aisles “baking ingredients”, “dog food care”, and “packaged vegetables fruits”. Include the number of times each item is ordered in your table.

```{r, message=FALSE}
instacart %>% 
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>% 
  count(aisle, product_name, name = "qty_purchased") %>% 
  arrange(desc(qty_purchased)) %>% 
  group_by(aisle) %>% 
  slice(1:3) %>% 
  kable(caption = 
          "Three Most Popular Items in Baking Ingredients, Dog Food Care, and Packaged Fruits &
           Veggies Aisles")
```

The most popular product in `baking ingredients` was Light Brown Sugar, which was purchased 499 times. 
The most popular product in `dog food care` was Snack Stick Chicken & Rice Recipe Dog Treats, which were ordered 30 times. 
The most popular product in `packaged vegetables fruits` was Organic Baby Spinach, which was purchased 9784 times. 

#### Make a table showing the mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week

```{r, message=FALSE}
  instacart %>% 
    filter(product_name %in% c(
      "Pink Lady Apples", "Coffee Ice Cream"
    )) %>% 
    group_by(product_name, order_dow) %>% 
    summarize(mean_time = mean(order_hour_of_day)) %>%
    mutate(
      mean_time = (mean_time*3600) %>% 
      seconds_to_period() %>% 
      hms(), 
      mean_time = period(
        second = round(second(mean_time), 0), 
        minute = minute(mean_time), 
        hour = hour(mean_time)
        ), 
      mean_time = as.POSIXct(mean_time, format = "%H:%M:%S", origin = lubridate::origin, tz = "UTC"), 
      mean_time = format(mean_time, "%I:%M:%S %p")
      ) %>% 
    pivot_wider(
      names_from = "order_dow", 
      values_from = "mean_time"
    ) %>% 
    kable(caption = "Average Time Coffee Ice Cream & Pink Lady Apples are Ordered per Day of Week")
```

The earliest and latest times `Coffee Ice Cream` is ordered are 12:15 PM on Friday and 3:22 PM on Tuesday. 
The earliest and latest time `Pink Lady Apples` are ordered are 11:21 AM on Monday and 2:15 PM on Wednesday. 

# Problem 2

#### Load BRFSS and clean data

```{r, load and clean BRFSS data, message=FALSE}
data("brfss_smart2010")

brfss <-
  brfss_smart2010 %>% 
  janitor::clean_names() %>% 
  rename(
    state = locationabbr,
    county = locationdesc
  ) %>% 
  filter(
    topic == "Overall Health"
  ) %>% 
  select(!(
    c(class, topic, display_order, data_value_unit, data_value_type, 
      data_value_footnote_symbol, data_source, class_id, topic_id, location_id,
      question_id, respid, geo_location
    )
  )) %>%
  mutate(
    county = str_remove_all(county, "^\\w\\w - ") %>% 
      str_remove_all(" County$"), 
    response = factor(
      response, ordered = T, levels = c(
        "Poor", "Fair", "Good", "Very good", "Excellent"
      )
    )
  )
```

#### In 2002, which states were observed at 7 or more locations? What about in 2010?

```{r, location 2002 and 2010, message=FALSE}
brfss %>% 
  filter(year == 2002) %>% 
  select(state, county) %>% 
  distinct() %>% 
  count(state) %>% 
  filter(n >= 7) %>% 
  arrange(desc(n)) %>% 
  kable(caption = "States observed 7 or more times, 2002")

brfss %>% 
  filter(year == 2010) %>% 
  select(state, county) %>% 
  distinct() %>% 
  count(state) %>% 
  filter(n >= 7) %>% 
  arrange(desc(n)) %>% 
  kable(caption = "States observed 7 or more times, 2010")
```

In 2002, of the states observed seven or more times, Pennsylvania was observed the most amount of times (10), and Connecticut, Florida, and North Carolina were observed the least amount of times (7). 

In 2010, of the states observed seven or more times, Florida was observed the most amount of times (41), and Colorado, Pennsylvania, and South Carolina were observed the least amount of times (7). 

#### Spaghetti plot of average data_value over time among 'Excellent' responses:

```{r, spaghetti plot, message=FALSE, warning=FALSE}
brfss %>% 
  filter(response == "Excellent") %>% 
  select(year, state, data_value) %>% 
  group_by(year, state) %>% 
  summarize(mean_data = mean(data_value)) %>% 
  ggplot(aes(x = year, y = mean_data, group = state)) +
    geom_line(aes(color = state), size = .6, alpha = .8) +
    xlab("Year") + ylab("Mean Data Value") +
    theme(
      legend.position = "right",
      legend.text = element_text(size = )
    ) +
    ggtitle(label = NULL, subtitle = "Average Data Value over Time among
            'Excellent' Responses") 

```

2002 is the `year` with the highest observed average `data_value`, and 2005 is the `year` with the lowest observed average `data_value`. From `r min(pull(brfss, year))` to `r max(pull(brfss, year))`, most states have an average `data_value` from 20 to 25, and there also appears to be a slight downward trend in average `data value` as time goes on. 

#### Make a two-panel plot showing, for the years 2006, and 2010, distribution of data_value for responses (“Poor” to “Excellent”) among locations in NY State.

```{r, two panel plot, message=FALSE, warning=FALSE}
brfss %>% 
  filter(year %in% c(2006, 2010) & state == "NY") %>% 
  ggplot(aes(x = data_value, fill = response)) +
    geom_density(alpha = .5) +
    xlab("Data Value") +
    theme(
      legend.position = "bottom",
      axis.title.y = element_blank()
          ) + 
    labs(fill = "Response") +
    facet_grid(rows = vars(year), switch = "y") +
    ggtitle("Data Value Distribution by Responses")
```

Overall, the distributions of `data value` by `response` for 2006 and 2010 are mostly similar with a few minor differences. In 2006, the observations for `data value` among those with Poor and Fair for `response` are not as spread out as it is in 2010. 

# Problem 3

#### Load, tidy, and otherwise wrangle the data. Your final dataset should include all originally observed variables and values; have useful variable names; include a weekday vs weekend variable; and encode data with reasonable variable classes. Describe the resulting dataset (e.g. what variables exist, how many observations, etc).

```{r, load and tidy, message=FALSE, warning=FALSE}
activity <-
  read_csv(file = "./Data/accel_data.csv")

activity <-
  activity %>% 
  janitor::clean_names() %>% 
  mutate(
    week = factor(week, ordered = T, levels = c(1:5)), 
    day = factor(day, ordered = T, 
                 levels = c("Sunday", "Monday", "Tuesday", "Wednesday",
                            "Thursday", "Friday", "Saturday")),
    weekday_or_weekend = ifelse(day %in% c("Saturday", "Sunday"),
                                "weekend", "weekday") %>% 
      factor(levels = c("weekday", "weekend"))
  ) %>% 
  relocate(weekday_or_weekend, .after = day)

names(activity) <-
  names(activity) %>% 
  str_replace_all("activity", "min")

activity <-
    activity %>% 
    pivot_longer(
      cols = starts_with("min_"), 
      names_to = "min", 
      names_prefix = "min_",
      values_to = "activity"
    ) %>% 
    mutate(
      min = as.numeric(min)
    )
```

The tidied data set has `r nrow(activity)` observations and `r ncol(activity)` where each observation represents a minute of observation on the accelerometer over the `r max(pull(activity, week))` weeks of observation. Key variables include:

`day id`: the day of observation, ranging from `r min(pull(activity, day_id))` to `r max(pull(activity, day_id))` days. 

`day`: day of the week observation takes place

`weekday_or_weekend`: a factor that determines if `day` takes place on weekday or weekend

`activity`: physical activity measured during that minute

#### Using your tidied dataset, aggregate accross minutes to create a total activity variable for each day, and create a table showing these totals. Are any trends apparent?

```{r, total activity per day, message=FALSE, warning=FALSE}
tot_act_per_day <-
  activity %>% 
  group_by(day_id, day) %>% 
  summarize(
    activity = sum(activity)
  )
   
tot_act_per_day %>% 
  kable(caption = "Total Activity per Day")

tot_act_per_day %>% 
  ggplot(aes(x = day, y = activity, group = day)) +
  geom_boxplot(aes(fill = day)) +
  xlab("Day of the Week") + ylab("Total Activity") +
  theme(
    legend.position = "none"
  ) +
  ggtitle("Total Activity by Day of the Week")
```

From the boxplot, we know that Wednesdays have the most consistent amount of total activity, while Saturdays are the most spread out. However, across all days of the week, there are similar values for the median. 

#### Make a single-panel plot that shows the 24-hour activity time courses for each day and use color to indicate day of the week. Describe in words any patterns or conclusions you can make based on this graph.

```{r, 24 hour activity by day of week, message=FALSE, warning=FALSE}
activity %>% 
  ggplot(aes(x = min, y = activity, group = day_id)) +
  geom_point(aes(color = day), size = .4, alpha = .5) +
  xlab("Minute") + ylab("Total Activity") +
  theme(
    legend.position = "right",
    legend.title = element_blank()
  ) + 
  ggtitle("24 Hour Activity by Day of Week")
```

The vast majority of the patients' total activity is clustered below an activity level of 2500 with only 3 observed minutes of the `r nrow(activity)` total minutes of observation exceeding an activity of 7500. 





